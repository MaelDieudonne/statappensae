```{r include=FALSE}
# Importation des données
mca_data <- load_parquet("mca_data.parquet")
detailed_mca_data <- load_parquet("detailed_mca_data.parquet")
map_data <- load_shapefile("FRANCE.shx")

codes_regions <- fread("data_other/codes_regions_Insee.csv", header = TRUE)
codes_regions$ABRV <- sapply(codes_regions$LIBELLE, get_first_letters)
```

```{r}
# Définition des variables
## Outcomes
mca_relative_outcomes <- c("part_T1", "part_T2", "GD_ratio_T1", "EC_ratio_T1", "EC_ratio_T2")
mca_absolute_outcomes <- c("part_T1", "part_T2", "DIns_ratio_T1", "GIns_ratio_T1", "DIns_ratio_T2", "EIns_ratio_T1", "CIns_ratio_T1", "EIns_ratio_T2", "CIns_ratio_T2")

mca_detailed_outcomes <- grep("^pvoix", names(detailed_mca_data), value = TRUE)
mca_detailed_outcomes <- c(mca_detailed_outcomes, "part_T1", "part_T2")

## Régresseurs
mca_regressors <- c("ppropri", "popcomm", "popagglo", "age", "prop1539", "prop4059", "prop60p", "propf", "propbac", "propsup", "pagri", "pindp", "pcadr", "ppint", "pempl", "pchom", "petranger", "revmoy", "pcrimesdelits", "mmoyfortune", "pisf", "prsa", "type_comm")
### Régresseurs abandonnés pour complaire aux économètres : prefract1791, pclerge1791, pclerge1856, pmessalisants1950
```

**Analyses descriptives**

Tableau récapitulatif (dont valeurs manquantes)

```{r}
nb_communes <- uniqueN(mca_data, by = "codecommune")

# Initialisation et calcul des valeurs
stat_desc <- data.table()
for (col in names(mca_data)) {if (!(col %in% c("dep", "codecommune", "codecommune2", "year", "GD_ratio_T2", "GIns_ratio_T2"))) {
  summary <- mca_data[, {
    fivenum_values <- fivenum(get(col))
    nan_count <- sum(is.na(get(col)))
    nan_count_prop <- round(100 * nan_count / nb_communes, 2)
    nan_pop <- sum(popcomm[is.na(get(col))], na.rm = TRUE)
    data.table(
      Variable = col,
      "Min" = round(fivenum_values[1], 0),
      "1er quartile" = fivenum_values[2],
      "Mediane" = fivenum_values[3],
      "3e quartile" = fivenum_values[4],
      "Max" = fivenum_values[5],
      "Valeurs manquantes" = nan_count,
      "En % des communes" = nan_count_prop
    )
  }]
stat_desc <- rbind(stat_desc, summary)
}}

stat_desc[] <- data.frame(lapply(stat_desc, tidy_table))
print(xtable(stat_desc, type = "latex"), file = "output/stat_desc_acm.tex")
print(stat_desc)

# Nettoyage
rm(col, nb_communes, stat_desc, summary)
```

Corrélogramme

```{r include=FALSE}
corr_variables <- c(mca_regressors, mca_relative_outcomes)
mca_corr_data <- mca_data[, ..corr_variables, with = FALSE]

mca_corr_data <- mca_corr_data[, .SD, .SDcols = sapply(mca_corr_data, is.numeric)]
mca_corr_data <- mca_corr_data[complete.cases(mca_corr_data)]

correlation_matrix <- cor(mca_corr_data)

png(filename = "output/corrplot.png", width = 2200, height = 1800)
corrplot(
  correlation_matrix,
  type = "upper",
  method = "color",
  order = "FPC",
  tl.cex = 3.5,
  tl.srt = 60,
  tl.col = "darkgrey",
  cl.cex = 3.5
)
dev.off()

rm(corr_variables, correlation_matrix, mca_corr_data)
```

**Régression linéaire simple**

```{r include=FALSE}
# Pour traiter le type de commune comme une variable catégorielle. Pour mémoire :
## 1 = villages (agglos <2000 hab)
## 2 = bourgs (agglos >2000 et <100 000 hab)
## 3 = banlieues (communes secondaires agglos >100 000 hab)
## 4 = métropoles (communes principales agglos >100 000 hab)
mca_data$type_comm <- factor(mca_data$type_comm)

relative_results <- list()
for (outcome in mca_relative_outcomes) {
  regression_formula <- as.formula(paste(outcome, "~", paste(mca_regressors, collapse = "+")))
  model_name <- paste0(outcome, "_model")
  relative_results[[model_name]] <- lm(regression_formula, data = mca_data)
}
suppressWarnings(stargazer(relative_results, type = "text"))
suppressWarnings(stargazer(relative_results, type = "latex", out = "output/2017_relative_results.tex"))

absolute_results <- list()
for (outcome in mca_absolute_outcomes) {
  regression_formula <- as.formula(paste(outcome, "~", paste(mca_regressors, collapse = "+")))
  model_name <- paste0(outcome, "_model")
  absolute_results[[model_name]] <- lm(regression_formula, data = mca_data)
}
suppressWarnings(stargazer(absolute_results, type = "text"))
suppressWarnings(stargazer(relative_results, type = "latex", out = "output/2017_absolute_results.tex"))

rm(model_name, outcome, regression_formula)
```

**ACP**

```{r}
# Préparation : ajout des modalités éliminées pour éviter la colinéarité dans les régressions, suppression des valeurs manquantes
variables_of_interest <- c(mca_detailed_outcomes, mca_regressors, "prop014", "propnodip", "pouvr")
mca_data_subset <- detailed_mca_data[, ..variables_of_interest]
mca_data_subset <- na.omit(mca_data_subset)

# Analyse
quant_regressors <- setdiff(variables_of_interest, mca_detailed_outcomes)
result <- PCA(mca_data_subset, scale.unit = TRUE, quanti.sup=quant_regressors, quali.sup = "type_comm")
var <- get_pca_var(result)

# Résultats
## Histogramme de la contribution des axes à la variance totale
fviz_screeplot(result, addlabels = TRUE, ylim = c(0, 50)) 
## Contribution des variables aux axes (comportements électoraux seulement)
print(result$var$contrib)
corrplot(var$contrib, is.corr = FALSE)
## Corrélation des variables aux axes (régresseurs inclus)
## Semble correspondre beaucoup à la qualité de représentation des variables

## Qualité de représentation des variables
corrplot(var$cos2, is.corr = FALSE) 
## Projection 
plot.PCA(result, axes=c(1,2), choix="var")
plot.PCA(result, axes=c(1,3), choix="var")
plot.PCA(result, axes=c(2,3), choix="var")

# Nettoyage
# rm(dummies, mca_data_subset, result, variables_of_interest, quant_regressors)
```

```{r}
print(result$quali.sup)

coeffs <- result$var$cor
labels <- rownames(result$var$cor)
axis_df <- data.frame(labels, coeffs, row.names = NULL)
colnames(axis_df) <- c("Variables", "Axe 1", "Axe 2", "Axe 3", "Axe 4", "Axe 5")
axis_tbl <- gt(axis_df)
data_color(axis_tbl, method = "numeric", columns = starts_with("Axe"), palette ="RdYlGn")

coeffs <- result$quanti.sup$cor
labels <- rownames(result$quanti.sup$cor)
axis_df <- data.frame(labels, coeffs, row.names = NULL)
colnames(axis_df) <- c("Variables", "Axe 1", "Axe 2", "Axe 3", "Axe 4", "Axe 5")
axis_tbl <- gt(axis_df)
data_color(axis_tbl, method = "numeric", columns = starts_with("Axe"), palette ="RdYlGn")

corrplot(result$quanti.sup$cor, is.corr = FALSE)
```

```{r}
axis <- dimdesc(result, axes=c(1:5))

correlation_values <- axis$Dim.1$quanti[, "correlation"]
labels <- rownames(axis$Dim.1$quanti)
axis_df <- data.frame(labels, correlation_values, row.names = NULL)
colnames(axis_df) <- c("Variables", "Axe 1")

correlation_values <- axis$Dim.1$quanti[, "correlation"]
labels <- rownames(axis$Dim.1$quanti)
axis_df <- data.frame(labels, correlation_values, row.names = NULL)
colnames(axis_df) <- c("Variables", "Axe 1")

correlation_values <- axis$Dim.2$quanti[, "correlation"]
labels <- rownames(axis$Dim.2$quanti)
df <- data.frame(labels, correlation_values, row.names = NULL)
colnames(df) <- c("Variables", "Axe 2")
axis_df <- merge(axis_df, df, by = "Variables", all = TRUE)

correlation_values <- axis$Dim.3$quanti[, "correlation"]
labels <- rownames(axis$Dim.3$quanti)
df <- data.frame(labels, correlation_values, row.names = NULL)
colnames(df) <- c("Variables", "Axe 3")
axis_df <- merge(axis_df, df, by = "Variables", all = TRUE)

correlation_values <- axis$Dim.4$quanti[, "correlation"]
labels <- rownames(axis$Dim.4$quanti)
df <- data.frame(labels, correlation_values, row.names = NULL)
colnames(df) <- c("Variables", "Axe 4")
axis_df <- merge(axis_df, df, by = "Variables", all = TRUE)

correlation_values <- axis$Dim.5$quanti[, "correlation"]
labels <- rownames(axis$Dim.5$quanti)
df <- data.frame(labels, correlation_values, row.names = NULL)
colnames(df) <- c("Variables", "Axe 5")
axis_df <- merge(axis_df, df, by = "Variables", all = TRUE)

rm(df)

axis_tbl <- gt(axis_df)
data_color(axis_tbl, method = "numeric", columns = starts_with("Axe"), palette ="RdYlGn")
```

```{r}
# Ajout des modalités éliminées pour éviter la colinéarité dans les régressions, suppression des valeurs manquantes, normalisation des variables numériques
variables_of_interest <- c(mca_regressors, "prop014", "propnodip", "pouvr", mca_detailed_outcomes)
mca_data_subset <- detailed_mca_data[, ..variables_of_interest]
mca_data_subset <- na.omit(mca_data_subset)
mca_data_subset[, names(mca_data_subset)[sapply(mca_data_subset, is.numeric)] := lapply(.SD, scale), .SDcols = names(mca_data_subset)]

# Création d'indicatrices pour les types de communes
mca_data_subset$type_comm <- as.factor(mca_data_subset$type_comm)
dummies <- model.matrix(~ type_comm - 1, data = mca_data_subset)
colnames(dummies) <- paste("type_comm", levels(mca_data_subset$type_comm), sep = "_")
mca_data_subset <- cbind(mca_data_subset, dummies)
mca_data_subset$type_comm <- NULL

# Analyse
result <- PCA(mca_data_subset, quanti.sup=mca_regressors,graph = TRUE)
fviz_screeplot(result, addlabels = TRUE, ylim = c(0, 50))
print(result$var$contrib)

var <- get_pca_var(result)
corrplot(var$contrib, is.corr = FALSE)
corrplot(var$cos2, is.corr = FALSE)

plot.PCA(result, axes=c(1,2), choix="ind", habillage=1)

# Nettoyage
rm(dummies, mca_data_subset, result, variables_of_interest)
```

```{r}
# Ajout des modalités éliminées pour éviter la colinéarité dans les régressions, suppression des valeurs manquantes, normalisation des variables numériques
variables_of_interest <- c(mca_regressors, "prop014", "propnodip", "pouvr", mca_detailed_outcomes)
mca_data_subset <- detailed_mca_data[, ..variables_of_interest]
mca_data_subset <- na.omit(mca_data_subset)
mca_data_subset[, names(mca_data_subset)[sapply(mca_data_subset, is.numeric)] := lapply(.SD, scale), .SDcols = names(mca_data_subset)]

# Création d'indicatrices pour les types de communes
mca_data_subset$type_comm <- as.factor(mca_data_subset$type_comm)
dummies <- model.matrix(~ type_comm - 1, data = mca_data_subset)
colnames(dummies) <- paste("type_comm", levels(mca_data_subset$type_comm), sep = "_")
mca_data_subset <- cbind(mca_data_subset, dummies)
mca_data_subset$type_comm <- NULL

outcome_variables <- mca_data_subset[, ..mca_detailed_outcomes]
pca_result <- prcomp(outcome_variables, scale. = TRUE)
var <- get_pca_var(pca_result)
projected_data <- predict(pca_result, newdata = mca_data_subset)

# Axes
fviz_screeplot(pca_result, addlabels = TRUE, ylim = c(0, 50))
## Contribution des variables
print(pca_result$rotation[, 1:5])
corrplot(var$contrib, is.corr = FALSE)
## Qualité de représentation des variables
corrplot(var$cos2, is.corr = FALSE)

fviz_pca_var(pca_result, axes = c(1, 2), geom = c("arrow", "text"), col.var = "blue", 
             fill.var = "transparent", alpha.var = 0.8)

fviz_pca_var(pca_result, axes = c(1, 3), geom = c("arrow", "text"), col.var = "red", 
             fill.var = "transparent", alpha.var = 0.8)
```

**K-means**

On commence par utiliser les résultats électoraux détaillés.

```{r}
# Préparation des données
variables <- c(mca_detailed_outcomes, mca_regressors, "prop014", "propnodip", "pouvr")
data_for_clustering <- detailed_mca_data[, ..variables]
data_for_clustering <- na.omit(data_for_clustering)
data_for_clustering <- scale(data_for_clustering)
```

```{r}
# Détermination du nombre de clusters optimal : méthode elbow
set.seed(123)
wcss <- numeric(length = 20)
for (i in 1:20) {
  kmeans_model <- kmeans(data_for_clustering, centers = i)
  wcss[i] <- kmeans_model$tot.withinss
}

plot(1:20, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-Cluster Sum of Squares (WCSS)")
```

Le point d'inflexion le plus flagrant est atteint pour k=4.

```{r}
# Détermination du nombre de clusters optimal : méthode silhouette
set.seed(123)
silhouette_avg <- numeric(length = 20)
for (i in 2:20) {
  kmeans_model <- kmeans(data_for_clustering, centers = i)
  sil <- silhouette(kmeans_model$cluster, dist(data_for_clustering))
  silhouette_avg[i - 1] <- mean(sil[, 3])
}
plot(2:20, silhouette_avg[2:20], type = "b", xlab = "Number of Clusters (k)", ylab = "Average Silhouette Width")
```

Ici, on obtient bien une courbe en cloche, avec un sommet atteint pour k=3. Les valeurs de Silhouette sont toutefois plus faibles qu'il faudrait.

```{r}
# Les deux lignes ci-dessous permettent de réaliser le clustering sur les seuls régresseurs. Mais on obtient des résultats moins faciles à interpréter...

## J'ai enlevé popagglo pour éviter que les résultats ne soient trop déformés en région parisienne.

data_for_clustering <- as.data.table(data_for_clustering)
mca_regressors <- c("ppropri", "popcomm", "age", "prop1539", "prop4059", "prop60p", "propf", "propbac", "propsup", "pagri", "pindp", "pcadr", "ppint", "pempl", "pchom", "petranger", "revmoy", "pcrimesdelits", "mmoyfortune", "pisf", "prsa", "type_comm")
data_for_clustering <- data_for_clustering[, ..mca_regressors]

set.seed(123)
kmeans_result <- kmeans(data_for_clustering, centers = 6)
cluster_assignments <- kmeans_result$cluster

variables <- c("codecommune", mca_detailed_outcomes, mca_regressors, "prop014", "propnodip", "pouvr")
data_for_clustering <- detailed_mca_data[, ..variables]
data_for_clustering <- na.omit(data_for_clustering)

data_for_clustering$cluster <- kmeans_result$cluster
data_for_clustering <- as.data.table(data_for_clustering)
data_for_clustering$type_comm <- as.factor(data_for_clustering$type_comm)

counts <- data_for_clustering[, .N, by = .(cluster, type_comm)]
total_counts <- data_for_clustering[, .N, by = cluster]
modality_share <- merge(counts, total_counts, by = "cluster")
modality_share[, share := N.x / N.y]
modality_share[, c("N.x", "N.y") := NULL]
modality_share <- dcast(modality_share, cluster ~ type_comm, value.var = "share")
setnames(modality_share, c("cluster", "% villages", "% bourgs", "% banlieues", "% métropoles"))

variables <- c(mca_detailed_outcomes, mca_regressors, "prop014", "propnodip", "pouvr")
variables <- setdiff(variables, "type_comm")
means <- data_for_clustering[, lapply(.SD, mean, na.rm = TRUE), by = cluster, .SDcols = variables]

means <- merge(means, modality_share, by = "cluster")
means[] <- data.frame(lapply(means, tidy_table))
print(means)
```

Les résultats ne sont pas vraiment exploitables, les clusters semblent extrêment similaires (ce qui est cohérent avec les faibles valeurs de Silhouette). On recommence avec les résultats électoraux agrégés.

```{r}
# Préparation des données
variables <- c(mca_relative_outcomes, mca_regressors, "prop014", "propnodip", "pouvr")
data_for_clustering <- mca_data[, ..variables]
data_for_clustering <- na.omit(data_for_clustering)
data_for_clustering <- scale(data_for_clustering)
```

```{r}
# Détermination du nombre de clusters optimal : méthode elbow
set.seed(123)
wcss <- numeric(length = 20)
for (i in 1:20) {
  kmeans_model <- kmeans(data_for_clustering, centers = i)
  wcss[i] <- kmeans_model$tot.withinss
}

plot(1:20, wcss, type = "b", xlab = "Number of Clusters", ylab = "Within-Cluster Sum of Squares (WCSS)")
```

A nouveau, pas de points d'inflexion vraiment flagrant. On pourrait choisir k=5.

```{r}
# Détermination du nombre de clusters optimal : méthode silhouette
set.seed(123)
silhouette_avg <- numeric(length = 20)
for (i in 2:20) {
  kmeans_model <- kmeans(data_for_clustering, centers = i)
  sil <- silhouette(kmeans_model$cluster, dist(data_for_clustering))
  silhouette_avg[i - 1] <- mean(sil[, 3])
}
plot(2:20, silhouette_avg[2:20], type = "b", xlab = "Number of Clusters (k)", ylab = "Average Silhouette Width")
```

Résultats pas très encourageants non plus... Les valeurs de Silhouette on été divisées par 10 par rapport au clustering sur les résultats détaillés. On retient finalement k=6.

```{r}
set.seed(123)
kmeans_result <- kmeans(data_for_clustering, centers = 6)
cluster_assignments <- kmeans_result$cluster

variables <- c("codecommune", mca_relative_outcomes, mca_regressors, "prop014", "propnodip", "pouvr")
data_for_clustering <- mca_data[, ..variables]
data_for_clustering <- na.omit(data_for_clustering)

data_for_clustering$cluster <- kmeans_result$cluster
data_for_clustering <- as.data.table(data_for_clustering)
data_for_clustering$type_comm <- as.factor(data_for_clustering$type_comm)

counts <- data_for_clustering[, .N, by = .(cluster, type_comm)]
total_counts <- data_for_clustering[, .N, by = cluster]
modality_share <- merge(counts, total_counts, by = "cluster")
modality_share[, share := N.x / N.y]
modality_share[, c("N.x", "N.y") := NULL]
modality_share <- dcast(modality_share, cluster ~ type_comm, value.var = "share")
setnames(modality_share, c("cluster", "% villages", "% bourgs", "% banlieues", "% métropoles"))

variables <- c(mca_relative_outcomes, mca_regressors, "prop014", "propnodip", "pouvr")
variables <- setdiff(variables, "type_comm")
means <- data_for_clustering[, lapply(.SD, mean, na.rm = TRUE), by = cluster, .SDcols = variables]

means <- merge(means, modality_share, by = "cluster")
means[] <- data.frame(lapply(means, tidy_table))
print(means)
```

Ici, les résultats sont plus intéressants, avec des clusters qui se différencient plus nettement ; les clusters 2 et 6 en particulier, avec des taux de propriétaires très en-dessous de la moyenne, mais l'un (n°6) qui vote beaucoup aux extrêmes, l'autre (n°2) qui vote davantage au centre. Essayons d'identifier / caractériser ces clusters.

Trois appartiennent à l'univers rural (avec le même taux de propriétaires) ; représentent environ 20 000 communes 4 = campagne paysanne, avec les plus petites communes, une proportion très élevée d'agriculteurs, une population plus âgée et moins diplômée qu'ailleurs. Cluster présentant le plus fort taux de propriétaires, participation dans la moyenne, vote à gauche le plus faible, ainsi que le vote protestataire au T1. Cluster le plus petit, correspondant à la droite rurale traditionnelle ? 1 et 5 = campagne ouvrière, avec toujours de petites communes et agglomérations, mais une population beaucoup plus ouvrière. Cluster 1 = population âgée, avec un peu plus de chômeurs et d'étrangers, plus de crimes et délits, ainsi que de bénéficiaires du RSA. Cluster 5 = population plus jeune. Vote à gauche faible, vote protestataire élevé. Univers pavillonnaire ?

Trois appartiennent à l'univers urbain (avec des taux variables de propriétaires) ; représentent environ 13 000 communes 2 = Agglomération parisienne et centre des métropoles, sans doute possible grâce à popagglo. Avec le plus faible taux de propriétaires, une population plus jeune et nettement plus diplômée qu'ailleurs, avec la plus grande proportion de cadres et celle d'ouvriers parmi les plus faibles. Avec aussi la situation économique la plus contrastée, associant le revenu communal moyen et la proportion de contribuables soumis à l'ISF les plus élevés, mais aussi la seconde plus importante proportion d'allocataires du RSA. Cluster où la participation est la plus faible, le vote à gauche le plus fort, et le vote protestataire le plus faible. Cluster le plus petit en nombre de communes. 6 = banlieues et villes pauvres ? 3 = petites communes appartenant à de grosses agglomérations, avec beaucoup de cadres et de professions intermédiaires, et de diplômés du supérieur. Communes très riches, comptant le moins d'étrangers et d'allocataires du RSA. Présentent la participation la plus élevée, un vote à gauche moyen, et un vote protestataire faible. Correspondent aux beaux quartiers hors des centres, banlieues aisées, périrubain riche ?

NB : les données sur le RSA sont manquantes pour la Corse. Celle-ci est donc exclue de la classification !

```{r}
draw_map_cluster <- function(region, base_width) {
  carto <- merge(map_data, data_for_clustering, by.x = "INSEE_COM", by.y = "codecommune", all.x = TRUE)
  carto[["cluster"]] <- factor(carto[["cluster"]])
  if (region != 0) {
    carto <- subset(carto, INSEE_REG == region)
    reg_name <- codes_regions$LIBELLE[codes_regions$REG == region]
    reg_abrv <- codes_regions$ABRV[codes_regions$REG == region]
  } else {
    reg_name <- "France"
    reg_abrv <- "FR"
  }

  output_file <- paste0("output/clusters_2017_", reg_abrv, ".png")
  title <- paste0("Clusters en ", reg_name)
  legend_labels <- c("1" = "Rural mixte",
                     "2" = "Centre des grandes villes",
                     "3" = "Périurbain aisé",
                     "4" = "Rural à dominante paysanne",
                     "5" = "Rural à dominante ouvrière",
                     "6" = "Banlieues et villes pauvres")
  legend_colors <- c("1" = "green",
                     "2" = "blue",
                     "3" = "skyblue",
                     "4" = "darkgreen",
                     "5" = "lightgreen",
                     "6" = "brown")
  
  # Exportation d'une carte en haute résolution
  ## Calcul des dimensions
  bbox <- st_bbox(carto)
  aspect_ratio <- diff(c(bbox$xmin, bbox$xmax)) / diff(c(bbox$ymin, bbox$ymax))
  base_height <- base_width / aspect_ratio
  font_size <- base_width * 2.2
  ## Création et enregistrement
  plot_png <- ggplot() +
    geom_sf(data = carto, aes(fill = .data[["cluster"]])) +
    ggtitle(paste(title)) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5, size = font_size),
          axis.text = element_blank(),
          panel.grid = element_blank(),
          plot.title.position = "plot",
          legend.title = element_text(size = font_size * 0.8),
          legend.text = element_text(size = font_size * 0.7)) +
    scale_fill_manual(values = legend_colors,
                      breaks = names(legend_labels),
                      labels = legend_labels,
                      name = NULL)
  ggsave(output_file, plot = plot_png, width = base_width, height = base_height, units = "in")
  
  display_plot <- ggplot() +
    geom_sf(data = carto, aes(fill = .data[["cluster"]])) +
    ggtitle(paste(title)) +
    theme_minimal() +
    theme(plot.title = element_text(hjust = 0.5),
          axis.text = element_blank(),
          panel.grid = element_blank(),
          plot.title.position = "plot",
          legend.title = element_text(),
          legend.text = element_text()) +
    scale_fill_manual(values = legend_colors,
                      breaks = names(legend_labels),
                      labels = legend_labels,
                      name = NULL)
    print(display_plot)
}

for (i in c(11, 24, 27, 28, 32, 44, 52, 53, 75, 76, 84, 93)) {
  draw_map_cluster(i, 8)
}
```
